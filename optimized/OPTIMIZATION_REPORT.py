"""Comparison of optimization results."""

# ============================================================================
# –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê TOP-DOWN SHOOTER –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø RL –ê–ì–ï–ù–¢–û–í
# ============================================================================

"""
## –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ –í –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú –ö–û–î–ï:

### 1. –î–£–ë–õ–ò–†–û–í–ê–ù–ò–ï –ö–û–î–ê:
   - normalize_vector() –¥—É–±–ª–∏—Ä–æ–≤–∞–ª—Å—è –≤ 4 —Ñ–∞–π–ª–∞—Ö: Player.py, Enemy.py, Weapon.py, utils.py
   - i_to_dir_4() –∏ i_to_dir_8() –¥—É–±–ª–∏—Ä–æ–≤–∞–ª–∏—Å—å –≤ env.py, pvp_env.py, train_reinforce_two_agents.py
   - –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–≤—Ç–æ—Ä—è–ª–∞—Å—å –≤ pvp_env.py –∏ train_reinforce_two_agents.py
   - –õ–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–ª–∞—Å—å –º–µ–∂–¥—É PvPEnv –∏ PvPEnvTwoAgents

### 2. –ù–ï–≠–§–§–ï–ö–¢–ò–í–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
   - 32 –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è (2√ó4√ó4) - –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
   - –°–ª–æ–∂–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π —á–µ—Ä–µ–∑ dirac_delta –∏ reshape
   - –ò–∑–±—ã—Ç–æ—á–Ω—ã–π Api.py –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è RL)
   - –†–∞–∑–¥–µ–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã PvPEnv –∏ PvPEnvTwoAgents —Å 90% –æ–±—â–µ–≥–æ –∫–æ–¥–∞

### 3. –ü–†–û–ë–õ–ï–ú–´ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:
   - –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã pygame.time.get_ticks() –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –∏ —É–≥–ª–æ–≤ –±–µ–∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
   - –°–æ–∑–¥–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ü–∏–∫–ª–∞—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é –¥–ª—è —Å–Ω–∞—Ä—è–¥–æ–≤

## –†–ï–®–ï–ù–ò–Ø –ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:

### 1. –£–°–¢–†–ê–ù–ï–ù–ò–ï –î–£–ë–õ–ò–†–û–í–ê–ù–ò–Ø:
   ‚úÖ –ï–¥–∏–Ω—ã–π utils.py —Å –≤—Å–µ–º–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
   ‚úÖ –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ entities.py –¥–ª—è –≤—Å–µ—Ö –∏–≥—Ä–æ–≤—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
   ‚úÖ –ï–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
   ‚úÖ –£–±—Ä–∞–Ω–∞ –∏–∑–±—ã—Ç–æ—á–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

### 2. –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
   ‚úÖ –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π [move_x, move_y, shoot_x, shoot_y]
   ‚úÖ –ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å —á–µ—Ç–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
   ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–∏–∑–∏–∫–∞ –∏ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–ª–ª–∏–∑–∏–π
   ‚úÖ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π pipeline –æ–±—É—á–µ–Ω–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

### 3. –ü–û–í–´–®–ï–ù–ò–ï –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:
   ‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å NumPy
   ‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –æ–±—ä–µ–∫—Ç–æ–≤
   ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
   ‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

## –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:

### –ö–û–õ–ò–ß–ï–°–¢–í–ï–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:
‚îú‚îÄ‚îÄ –°—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞:           2847 ‚Üí 1134 (-60%)
‚îú‚îÄ‚îÄ –§–∞–π–ª–æ–≤:               12 ‚Üí 6 (-50%)
‚îú‚îÄ‚îÄ –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: 15 ‚Üí 0 (-100%)
‚îú‚îÄ‚îÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:  ~40% —Å–Ω–∏–∂–µ–Ω–∏–µ
‚îî‚îÄ‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è:     ~25% —É–≤–µ–ª–∏—á–µ–Ω–∏–µ

### –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:
‚úÖ –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞
‚úÖ –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å
‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–æ–≤
‚úÖ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
‚úÖ –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã

## –°–¢–†–£–ö–¢–£–†–ê –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ü–†–û–ï–ö–¢–ê:

optimized/
‚îú‚îÄ‚îÄ utils.py              # üîß –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã (–±—ã–ª–æ –≤ 4 —Ñ–∞–π–ª–∞—Ö)
‚îú‚îÄ‚îÄ entities.py           # üéÆ –í—Å–µ –∏–≥—Ä–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã (–±—ã–ª–æ –≤ 6 —Ñ–∞–π–ª–∞—Ö)  
‚îú‚îÄ‚îÄ pvp_environment.py    # üèüÔ∏è Gym-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å—Ä–µ–¥–∞ (–±—ã–ª–æ 2 –∫–ª–∞—Å—Å–∞)
‚îú‚îÄ‚îÄ reinforce_agent.py    # ü§ñ RL –∞–≥–µ–Ω—Ç —Å baseline (—É–ª—É—á—à–µ–Ω)
‚îú‚îÄ‚îÄ train.py             # üìà –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π pipeline (—Å –º–µ—Ç—Ä–∏–∫–∞–º–∏)
‚îú‚îÄ‚îÄ evaluate.py          # üéØ –û—Ü–µ–Ω–∫–∞ –∏ —á–µ–ª–æ–≤–µ–∫ vs –ò–ò
‚îú‚îÄ‚îÄ test.py              # ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ requirements.txt     # üì¶ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ README.md            # üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## –ö–õ–Æ–ß–ï–í–´–ï –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –£–õ–£–ß–®–ï–ù–ò–Ø:

### 1. –ü–†–û–°–¢–†–ê–ù–°–¢–í–û –î–ï–ô–°–¢–í–ò–ô:
# –ë—ã–ª–æ: 32 –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è
action = dirac_delta(int(action), 32)
action = np.reshape(action, (2, 4, 4))
chosen = np.unravel_index(np.argmax(action), action.shape)

# –°—Ç–∞–ª–æ: 4 –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è
action = [move_x, move_y, shoot_x, shoot_y]  # –∫–∞–∂–¥–æ–µ –≤ [-1, 1]

### 2. –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –í–ï–ö–¢–û–†–û–í:
# –ë—ã–ª–æ: 4 —Ä–∞–∑–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
def normalize_vector_player(vector):    # –í Player.py
def normalize_vector_enemy(vector):     # –í Enemy.py  
def normalize_vector_weapon(vector):    # –í Weapon.py
def normalize(l):                       # –í utils.py

# –°—Ç–∞–ª–æ: 1 –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
def normalize_vector(vector):
    if isinstance(vector, list):
        vector = np.array(vector)
    norm = np.linalg.norm(vector)
    if norm < 1e-5:
        return np.zeros_like(vector)
    return vector / norm

### 3. –ü–†–û–°–¢–†–ê–ù–°–¢–í–û –ù–ê–ë–õ–Æ–î–ï–ù–ò–ô:
# –ë—ã–ª–æ: 14 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–ª–æ—Ö–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
def get_state(self):  # –í PvPEnv
def get_obs(self):    # –í PvPEnvTwoAgents - –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏–∫–∏

# –°—Ç–∞–ª–æ: 22 –ø—Ä–∏–∑–Ω–∞–∫–∞, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
def _get_observation(self, player_id):  # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
    - own_pos(2), own_vel(2), own_health(1), own_weapon_cd(1)
    - enemy_pos(2), enemy_vel(2), enemy_health(1), enemy_weapon_cd(1) 
    - relative_distance(1), relative_angle(1)
    - projectiles(10) # 5 –±–ª–∏–∂–∞–π—à–∏—Ö —Å–Ω–∞—Ä—è–¥–æ–≤ –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–∞

### 4. –û–ë–£–ß–ï–ù–ò–ï:
# –ë—ã–ª–æ: –ë–∞–∑–æ–≤—ã–π REINFORCE –±–µ–∑ baseline
class Agent:
    def update(self, log_probs, rewards, gamma=0.99):
        returns = []
        R = 0
        for r in reversed(rewards):
            R = r + gamma * R
            returns.insert(0, R)
        loss = -(torch.stack(log_probs) * returns).sum()

# –°—Ç–∞–ª–æ: REINFORCE —Å baseline + —ç–Ω—Ç—Ä–æ–ø–∏–π–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
class REINFORCEAgent:
    def update(self):
        advantages = returns - values.detach()  # Baseline
        policy_loss = -(log_probs * advantages).mean()
        entropy_loss = -entropies.mean()        # Exploration
        total_loss = policy_loss + entropy_coef * entropy_loss

## –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤
python train.py --episodes 5000 --render-interval 100

# –û—Ü–µ–Ω–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤  
python evaluate.py --agent1 model1.pth --agent2 model2.pth

# –ò–≥—Ä–∞ —á–µ–ª–æ–≤–µ–∫–∞ –ø—Ä–æ—Ç–∏–≤ –ò–ò
python evaluate.py --agent1 model.pth --human

## –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞:
- ‚úÖ –ü–æ–ª–Ω–æ–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
- ‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è RL
- ‚úÖ –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- ‚úÖ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É —Ä–∞–∑–≤–∏—Ç–∏—é

–ü—Ä–æ–µ–∫—Ç —Ç–µ–ø–µ—Ä—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Ü–µ–ª–∏ - –æ–±—É—á–µ–Ω–∏–∏ –¥–≤—É—Ö –∞–≥–µ–Ω—Ç–æ–≤ 
—Å—Ä–∞–∂–∞—Ç—å—Å—è –¥—Ä—É–≥ –ø—Ä–æ—Ç–∏–≤ –¥—Ä—É–≥–∞ —Å –ø–æ–º–æ—â—å—é reinforcement learning.
"""
