#!/bin/bash

# –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Ç–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
# –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã, –æ–±–æ—Ä–æ–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —à—Ç—Ä–∞—Ñ—ã –∏ —Ñ–æ–∫—É—Å –Ω–∞ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏

echo "üéØ –ó–∞–ø—É—Å–∫ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è..."
echo "üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:"
echo "   ‚Ä¢ –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∏–≥—Ä–∞: W_KILL = 50.0, W_TICK = -0.005"
echo "   ‚Ä¢ –û–±–æ—Ä–æ–Ω–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: W_HIT = -2.0, W_WALL = -1.0"  
echo "   ‚Ä¢ –§–æ–∫—É—Å –Ω–∞ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏: W_DIST = 1.0, OPT_DIST = 150"
echo ""

python train.py \
    --episodes 2000 \
    --lr 0.001 \
    --save-interval 200 \
    --gamma 0.99 \
    --entropy-coef 0.01 \
    --hidden-dims 256 128 64 \
    --grad-clip 0.5 \
    --screen-size 400 400 \
    --max-steps 600 \
    --player-speed 450.0 \
    --player-health 3 \
    --reward-damage 1.0 \
    --reward-hit -2.0 \
    --reward-kill 50.0 \
    --reward-tick -0.005 \
    --reward-wall -1.0 \
    --reward-distance 1.0 \
    --optimal-distance 150 \
    --distance-tolerance 100 \
    --pistol-cooldown 250 \
    --shotgun-cooldown 750 \
    --machinegun-cooldown 100 \
    --projectile-speed 300.0 \
    --tensorboard-dir "tb/tactical_aggressive" \
    --checkpoint-dir "checkpoints/tactical_aggressive" \
    --verbose

echo ""
echo "‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
echo "üìä –î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: tensorboard --logdir tb/tactical_aggressive"
echo "üéÆ –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: python evaluate.py --agent1 checkpoints/tactical_aggressive/final_model_agent1.pth --hidden-dims 256 128 64"
